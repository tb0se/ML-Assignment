{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier for job postings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this dataset we try to classify whether a job posting is fraudulent or not based on some features of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "#import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('job_postings_excel.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features and the target class of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: \n",
      " ['title' 'location' 'department' 'salary_range' 'company_profile'\n",
      " 'description' 'requirements' 'benefits' 'telecommuting'\n",
      " 'has_company_logo' 'has_questions' 'employment_type'\n",
      " 'required_experience' 'required_education' 'industry' 'function'] \n",
      "\n",
      "target class: \n",
      " fraudulent\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = df.columns[1:df.columns.shape[0]-1].to_numpy()\n",
    "print('features:', '\\n', features, '\\n')\n",
    "\n",
    "target_class = df.columns[df.columns.shape[0]-1]\n",
    "print('target class:', '\\n', target_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute priors of any job posting being fraudulent and not being fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class lables:  [0 1] \n",
      " class labels counts:  [17014   866] \n",
      "\n",
      "prior probability job posting IS NOT fraudulent:  0.9515659955257271 \n",
      "\n",
      "prior probability job posting IS fraudulent:  0.04843400447427293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class_lables, class_lables_counts = np.unique(df['fraudulent'], return_counts=True)\n",
    "\n",
    "prior_prob_fraud_false = class_lables_counts[0] / np.sum(class_lables_counts)\n",
    "prior_prob_fraud_true = 1 - prior_prob_fraud_false\n",
    "\n",
    "print('class lables: ', class_lables, '\\n', 'class labels counts: ', class_lables_counts, '\\n')\n",
    "print('prior probability job posting IS NOT fraudulent: ', prior_prob_fraud_false, '\\n')\n",
    "print('prior probability job posting IS fraudulent: ', prior_prob_fraud_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split dataset into training, validation and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data example item: \n",
      "\n",
      " job_id                                                                 1\n",
      "title                                                   Marketing Intern\n",
      "location                                                   US,NY,NewYork\n",
      "department                                                     Marketing\n",
      "salary_range                                                         NaN\n",
      "company_profile        We're Food52, and we've created a groundbreaki...\n",
      "description            Food52, a fast-growing, James Beard Award-winn...\n",
      "requirements           Experience with content management systems a m...\n",
      "benefits                                                             NaN\n",
      "telecommuting                                                          0\n",
      "has_company_logo                                                       1\n",
      "has_questions                                                          0\n",
      "employment_type                                                    Other\n",
      "required_experience                                           Internship\n",
      "required_education                                                   NaN\n",
      "industry                                                             NaN\n",
      "function                                                       Marketing\n",
      "fraudulent                                                             0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data = df.loc[:10728]\n",
    "validation_data = df.loc[10729:16450]\n",
    "test_data = df.loc[16451:]\n",
    "\n",
    "print('training data example item:','\\n\\n', training_data.loc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to compute fraudulent counts of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now this function is only applied to the title feature\n",
    "# we will try with 50 unique titles since considering all the unique titles slows computation\n",
    "\n",
    "def compute_fraud_counts(class_labels, feature_full_data, feature_unique_data):\n",
    "\n",
    "    feature_unique_data_fraud_counts = {}\n",
    "    fraud_count_false = 0\n",
    "    fraud_count_true = 0\n",
    "\n",
    "    for j in range(50):\n",
    "        for i in range(class_labels.shape[0]):    \n",
    "\n",
    "            if class_labels[i] == 0 and feature_full_data[i] == feature_unique_data[j]:\n",
    "                fraud_count_false += 1\n",
    "                \n",
    "            elif class_labels[i] == 1 and feature_full_data[i] == feature_unique_data[j]:\n",
    "                fraud_count_true += 1\n",
    "\n",
    "        feature_unique_data_fraud_counts[feature_unique_data[j]] = [fraud_count_false, fraud_count_true]\n",
    "        fraud_count_false = 0\n",
    "        fraud_count_true = 0\n",
    "        \n",
    "    return feature_unique_data_fraud_counts\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to compute fraudulent counts for features with binary data (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's different between this function and the one above is that for features with binary data we dont have to worry\n",
    "# about the size of unique values unlike with features that can take on multiple values which can increase the\n",
    "# size of unique values we have to consider for computation.\n",
    "\n",
    "def compute_fraud_counts_binary_data(class_labels, feature_full_data, feature_unique_data):\n",
    "\n",
    "    feature_unique_data_fraud_counts = {}\n",
    "    fraud_count_false = 0\n",
    "    fraud_count_true = 0\n",
    "\n",
    "    for value in feature_unique_data:\n",
    "        for i in range(class_labels.shape[0]):    \n",
    "\n",
    "            if class_labels[i] == 0 and feature_full_data[i] == value:\n",
    "                fraud_count_false += 1\n",
    "                \n",
    "            elif class_labels[i] == 1 and feature_full_data[i] == value:\n",
    "                fraud_count_true += 1\n",
    "\n",
    "        feature_unique_data_fraud_counts[value] = [fraud_count_false, fraud_count_true]\n",
    "        fraud_count_false = 0\n",
    "        fraud_count_true = 0\n",
    "        \n",
    "    return feature_unique_data_fraud_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to compute fraudulent counts for features employment_type, required_education and required_experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is applied to the named features since the size of unique values in each of these features is not large\n",
    "# to the point it slows down computation\n",
    "\n",
    "def compute_fraud_counts_feature(class_labels, feature_full_data, feature_unique_data):\n",
    "    \n",
    "    feature_unique_data_fraud_counts = {}\n",
    "    fraud_count_false = 0\n",
    "    fraud_count_true = 0\n",
    "\n",
    "    for value in feature_unique_data:\n",
    "\n",
    "        for i in range(class_labels.shape[0]):\n",
    "\n",
    "            if str(feature_full_data[i]) == 'nan':\n",
    "\n",
    "                if str(value) == 'nan':\n",
    "\n",
    "                    if class_labels[i] == 0:\n",
    "                        fraud_count_false += 1\n",
    "                        \n",
    "                    elif class_labels[i] == 1:\n",
    "                        fraud_count_true += 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                if str(value) != 'nan':\n",
    "\n",
    "                    if class_labels[i] == 0 and value == feature_full_data[i]:\n",
    "                        fraud_count_false += 1\n",
    "\n",
    "                    elif class_labels[i] == 1 and value == feature_full_data[i]:\n",
    "                        fraud_count_true += 1\n",
    "\n",
    "        feature_unique_data_fraud_counts[value] = [fraud_count_false, fraud_count_true]\n",
    "        fraud_count_false = 0\n",
    "        fraud_count_true = 0\n",
    "        \n",
    "    return feature_unique_data_fraud_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to compute probabilities of unique values of each feature with respect to each class label and applies laplacian smoothing if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_probabilities(feature_values_fraud_counts):\n",
    "    \n",
    "    feature_values_fraud_prob = {}\n",
    "\n",
    "    for key in feature_values_fraud_counts:\n",
    "        \n",
    "        if feature_values_fraud_counts[key][0] == 0 or feature_values_fraud_counts[key][1] == 0:\n",
    "            \n",
    "            # apply laplacian by adding a fake datapoint count to both counts of each class label\n",
    "            feature_value_freq_with_laplacian = sum(feature_values_fraud_counts[key]) + 2\n",
    "            prob_fraud_false = (feature_values_fraud_counts[key][0] + 1) / feature_value_freq_with_laplacian\n",
    "            prob_fraud_true = (feature_values_fraud_counts[key][1] + 1) / feature_value_freq_with_laplacian\n",
    "\n",
    "        else:\n",
    "            \n",
    "            feature_value_freq = sum(feature_values_fraud_counts[key])\n",
    "            prob_fraud_false = feature_values_fraud_counts[key][0] / feature_value_freq\n",
    "            prob_fraud_true = feature_values_fraud_counts[key][1] / feature_value_freq\n",
    "\n",
    "        feature_values_fraud_prob[key] = [prob_fraud_false, prob_fraud_true]\n",
    "        \n",
    "    return feature_values_fraud_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function for printing dictionary values in formatted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_dictionary(dictionary):\n",
    "    for key,value in dictionary.items():\n",
    "        print(\"{} {}\".format(key, value))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique title with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title [title_fraud_false, title_fraud_true] \n",
      "\n",
      "marketing intern [11, 0]\n",
      "customer service - cloud video production [1, 0]\n",
      "commissioning machinery assistant (cma) [1, 0]\n",
      "account executive - washington dc [1, 0]\n",
      "bill review manager [1, 0]\n",
      "accounting clerk [1, 1]\n",
      "head of content (m/f) [1, 0]\n",
      "lead guest service specialist [1, 0]\n",
      "hp bsm sme [2, 0]\n",
      "customer service associate - part time [64, 0]\n",
      "asp.net developer job opportunity at united states,new jersey [1, 0]\n",
      "talent sourcer (6 months fixed-term contract) [1, 0]\n",
      "applications developer, digital [1, 0]\n",
      "installers [2, 0]\n",
      "account executive - sydney [1, 0]\n",
      "vp of sales - vault dragon [1, 0]\n",
      "hands-on qa leader [1, 0]\n",
      "southend-on-sea traineeships under nas 16-18 year olds only [1, 0]\n",
      "visual designer [6, 0]\n",
      "process controls engineer - dcs plc ms office - pa [1, 0]\n",
      "marketing assistant [8, 0]\n",
      "front end developer [26, 0]\n",
      "engagement manager [4, 0]\n",
      "vice president, sales and sponsorship (businessfriend.com) [1, 0]\n",
      "customer service [2, 0]\n",
      "h1b sponsor for l1/l2/opt [2, 0]\n",
      "marketing exec [2, 0]\n",
      "haad/dha licensed doctors opening in uae [1, 0]\n",
      "talent management process manager [6, 0]\n",
      "customer service associate [135, 0]\n",
      "customer service technical specialist [23, 0]\n",
      "software applications specialist [1, 0]\n",
      "craftsman associate [1, 0]\n",
      "completion engineer [4, 0]\n",
      "i want to work at karmarama [1, 0]\n",
      "english teacher abroad [264, 0]\n",
      "graduates: english teacher abroad [52, 0]\n",
      "project manager [36, 0]\n",
      "art director [5, 0]\n",
      "receptionist/customer service technical specialist [1, 0]\n",
      "jr. developer [2, 0]\n",
      "customer service associate receptionist [1, 0]\n",
      "customer service team lead [38, 0]\n",
      "inside sales professional-omaha [3, 0]\n",
      "entry level [1, 0]\n",
      "food production manager @ pgi, a food production company [1, 0]\n",
      "administrative/front desk [1, 0]\n",
      "payroll tax specialist [1, 0]\n",
      "technical project manager [9, 0]\n",
      "outside sales professional-st. cloud [1, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_titles = training_data['title'].str.lower()\n",
    "unique_titles = np.array(training_data_titles.drop_duplicates())\n",
    "\n",
    "titles_and_fraud_counts = compute_fraud_counts(training_data['fraudulent'], training_data_titles, unique_titles)\n",
    "\n",
    "print('title [title_fraud_false, title_fraud_true]', '\\n')\n",
    "print_dictionary(titles_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique title with respect to the class labes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title [prob_title_fraud_false, prob_title_fraud_true] \n",
      "\n",
      "marketing intern [0.9230769230769231, 0.07692307692307693]\n",
      "customer service - cloud video production [0.6666666666666666, 0.3333333333333333]\n",
      "commissioning machinery assistant (cma) [0.6666666666666666, 0.3333333333333333]\n",
      "account executive - washington dc [0.6666666666666666, 0.3333333333333333]\n",
      "bill review manager [0.6666666666666666, 0.3333333333333333]\n",
      "accounting clerk [0.5, 0.5]\n",
      "head of content (m/f) [0.6666666666666666, 0.3333333333333333]\n",
      "lead guest service specialist [0.6666666666666666, 0.3333333333333333]\n",
      "hp bsm sme [0.75, 0.25]\n",
      "customer service associate - part time [0.9848484848484849, 0.015151515151515152]\n",
      "asp.net developer job opportunity at united states,new jersey [0.6666666666666666, 0.3333333333333333]\n",
      "talent sourcer (6 months fixed-term contract) [0.6666666666666666, 0.3333333333333333]\n",
      "applications developer, digital [0.6666666666666666, 0.3333333333333333]\n",
      "installers [0.75, 0.25]\n",
      "account executive - sydney [0.6666666666666666, 0.3333333333333333]\n",
      "vp of sales - vault dragon [0.6666666666666666, 0.3333333333333333]\n",
      "hands-on qa leader [0.6666666666666666, 0.3333333333333333]\n",
      "southend-on-sea traineeships under nas 16-18 year olds only [0.6666666666666666, 0.3333333333333333]\n",
      "visual designer [0.875, 0.125]\n",
      "process controls engineer - dcs plc ms office - pa [0.6666666666666666, 0.3333333333333333]\n",
      "marketing assistant [0.9, 0.1]\n",
      "front end developer [0.9642857142857143, 0.03571428571428571]\n",
      "engagement manager [0.8333333333333334, 0.16666666666666666]\n",
      "vice president, sales and sponsorship (businessfriend.com) [0.6666666666666666, 0.3333333333333333]\n",
      "customer service [0.75, 0.25]\n",
      "h1b sponsor for l1/l2/opt [0.75, 0.25]\n",
      "marketing exec [0.75, 0.25]\n",
      "haad/dha licensed doctors opening in uae [0.6666666666666666, 0.3333333333333333]\n",
      "talent management process manager [0.875, 0.125]\n",
      "customer service associate [0.9927007299270073, 0.0072992700729927005]\n",
      "customer service technical specialist [0.96, 0.04]\n",
      "software applications specialist [0.6666666666666666, 0.3333333333333333]\n",
      "craftsman associate [0.6666666666666666, 0.3333333333333333]\n",
      "completion engineer [0.8333333333333334, 0.16666666666666666]\n",
      "i want to work at karmarama [0.6666666666666666, 0.3333333333333333]\n",
      "english teacher abroad [0.9962406015037594, 0.0037593984962406013]\n",
      "graduates: english teacher abroad [0.9814814814814815, 0.018518518518518517]\n",
      "project manager [0.9736842105263158, 0.02631578947368421]\n",
      "art director [0.8571428571428571, 0.14285714285714285]\n",
      "receptionist/customer service technical specialist [0.6666666666666666, 0.3333333333333333]\n",
      "jr. developer [0.75, 0.25]\n",
      "customer service associate receptionist [0.6666666666666666, 0.3333333333333333]\n",
      "customer service team lead [0.975, 0.025]\n",
      "inside sales professional-omaha [0.8, 0.2]\n",
      "entry level [0.6666666666666666, 0.3333333333333333]\n",
      "food production manager @ pgi, a food production company [0.6666666666666666, 0.3333333333333333]\n",
      "administrative/front desk [0.6666666666666666, 0.3333333333333333]\n",
      "payroll tax specialist [0.6666666666666666, 0.3333333333333333]\n",
      "technical project manager [0.9090909090909091, 0.09090909090909091]\n",
      "outside sales professional-st. cloud [0.6666666666666666, 0.3333333333333333]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "titles_and_fraud_prob = compute_probabilities(titles_and_fraud_counts)\n",
    "\n",
    "print('title [prob_title_fraud_false, prob_title_fraud_true]', '\\n')\n",
    "print_dictionary(titles_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### location feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique location with respect to the class lables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 subsets of locations: \n",
      " [['us', 'ny', 'newyork'], ['nz', 'auckland'], ['us', 'ia', 'wever'], ['us', 'dc', 'washington'], ['us', 'fl', 'fortworth'], ['us', 'md'], ['de', 'be', 'berlin'], ['us', 'ca', 'sanfrancisco'], ['us', 'fl', 'pensacola'], ['us', 'az', 'phoenix'], ['us', 'nj', 'jerseycity'], ['gb', 'lnd', 'london'], ['us', 'ct', 'stamford'], ['us', 'fl', 'orlando'], ['au', 'nsw', 'sydney'], ['sg', '01', 'singapore'], ['il', 'telaviv', 'israel'], ['gb', 'sos', 'southend-on-sea'], ['us', 'ny', 'newyork'], ['us', 'pa', 'usanortheast']] \n",
      "\n",
      "unique locations: \n",
      " ['us', 'ny', 'newyork', 'nz', 'auckland', 'ia', 'wever', 'dc', 'washington', 'fl', 'fortworth', 'md', 'de', 'be', 'berlin', 'ca', 'sanfrancisco', 'pensacola', 'az', 'phoenix', 'nj', 'jerseycity', 'gb', 'lnd', 'london', 'ct', 'stamford', 'orlando', 'au', 'nsw', 'sydney', 'sg', '01', 'singapore', 'il', 'telaviv', 'israel', 'sos', 'southend-on-sea', 'pa', 'usanortheast']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_locations = training_data['location'].str.lower()\n",
    "locations = []\n",
    "unique_locations = []\n",
    "\n",
    "# note: even though we have some nan values it could mean that if a job posting does not have a location then its likely\n",
    "# that its fraudulent or the location data for the job posting was not provided, thus we have to consider a nan value\n",
    "# to mean job posting has no location so to say. Similar explanation for subsequent features where nan values are present\n",
    "\n",
    "# get locations\n",
    "for i in range(training_data_locations.shape[0]):\n",
    "    \n",
    "    if str(training_data_locations[i]) == 'nan':\n",
    "        locations.append( training_data_locations[i] )\n",
    "        \n",
    "    else:\n",
    "        locations.append( training_data_locations[i].split(',') )\n",
    "\n",
    "# from the collected locations get unique locations (note: location=nan is also included in unique locations for the\n",
    "# reasons mentioned above). we will also consider a small set of locations due to dataset being too large for computation.\n",
    "# we will consider 10 location subsets and from the 10 subsets in locations list we pick unique locations.\n",
    "# note: it would be hard to decide which locations have abbreviations and their full names in the same subset, so\n",
    "# we will treate them differently (i.e if locations[j] = [us,ny,newyork] we treat ny & newyork different)\n",
    "\n",
    "for j in range(20):\n",
    "    locations_subset = locations[j]\n",
    "    \n",
    "    if str(locations_subset) == 'nan':\n",
    "        if locations_subset not in unique_locations:\n",
    "            unique_locations.append(locations_subset)\n",
    "        \n",
    "    else:\n",
    "        for k in range(len(locations_subset)):\n",
    "            if locations_subset[k] not in unique_locations:\n",
    "                unique_locations.append(locations_subset[k])\n",
    "\n",
    "print('20 subsets of locations:', '\\n', locations[:20], '\\n')\n",
    "print('unique locations:', '\\n', unique_locations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location [location_fraud_false, location_fraud_true] \n",
      "\n",
      "us [5856, 404]\n",
      "ny [734, 32]\n",
      "newyork [413, 5]\n",
      "nz [198, 0]\n",
      "auckland [143, 0]\n",
      "ia [45, 2]\n",
      "wever [1, 0]\n",
      "dc [221, 1]\n",
      "washington [213, 1]\n",
      "fl [199, 16]\n",
      "fortworth [18, 4]\n",
      "md [53, 18]\n",
      "de [234, 1]\n",
      "be [228, 0]\n",
      "berlin [150, 0]\n",
      "ca [1396, 86]\n",
      "sanfrancisco [261, 5]\n",
      "pensacola [5, 1]\n",
      "az [87, 1]\n",
      "phoenix [43, 1]\n",
      "nj [116, 2]\n",
      "jerseycity [11, 0]\n",
      "gb [1414, 11]\n",
      "lnd [605, 3]\n",
      "london [678, 3]\n",
      "ct [82, 2]\n",
      "stamford [12, 0]\n",
      "orlando [17, 2]\n",
      "au [93, 5]\n",
      "nsw [48, 2]\n",
      "sydney [30, 2]\n",
      "sg [43, 0]\n",
      "01 [23, 0]\n",
      "singapore [14, 0]\n",
      "il [282, 8]\n",
      "telaviv [19, 0]\n",
      "israel [1, 0]\n",
      "sos [1, 0]\n",
      "southend-on-sea [1, 0]\n",
      "pa [179, 8]\n",
      "usanortheast [1, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for each unique location get counts of fraudulent=0 and fraudulent=1\n",
    "\n",
    "locations_and_fraud_counts = {}\n",
    "location_fraud_false = 0\n",
    "location_fraud_true = 0\n",
    "\n",
    "for location in unique_locations:\n",
    "        \n",
    "    for i in range(training_data['fraudulent'].shape[0]):\n",
    "\n",
    "        if str(locations[i]) == 'nan':\n",
    "\n",
    "            # for locations[i] == nan value, we only have to consider whether the specific location is a nan value\n",
    "            # and if its not, continue with the next iteration on i\n",
    "            \n",
    "            if str(location) == 'nan':\n",
    "\n",
    "                if training_data['fraudulent'].loc[i] == 0:\n",
    "                    location_fraud_false += 1\n",
    "                    \n",
    "                elif training_data['fraudulent'].loc[i] == 1:\n",
    "                    location_fraud_true += 1\n",
    "\n",
    "        else:\n",
    "            # for valid locations we only have to consider a location with a non nan value.\n",
    "            \n",
    "            if str(location) != 'nan':\n",
    "\n",
    "                if training_data['fraudulent'].loc[i] == 0 and location in locations[i]:\n",
    "                    location_fraud_false += 1\n",
    "\n",
    "                elif training_data['fraudulent'].loc[i] == 1 and location in locations[i]:\n",
    "                    location_fraud_true += 1\n",
    "\n",
    "    locations_and_fraud_counts[location] = [location_fraud_false, location_fraud_true]\n",
    "    location_fraud_false = 0\n",
    "    location_fraud_true = 0\n",
    "    \n",
    "print('location [location_fraud_false, location_fraud_true]', '\\n')\n",
    "print_dictionary(locations_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute the probabilities of each unique location with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location [prob_location_fraud_false, prob_location_fraud_true] \n",
      "\n",
      "us [0.9354632587859425, 0.0645367412140575]\n",
      "ny [0.95822454308094, 0.04177545691906005]\n",
      "newyork [0.9880382775119617, 0.011961722488038277]\n",
      "nz [0.995, 0.005]\n",
      "auckland [0.993103448275862, 0.006896551724137931]\n",
      "ia [0.9574468085106383, 0.0425531914893617]\n",
      "wever [0.6666666666666666, 0.3333333333333333]\n",
      "dc [0.9954954954954955, 0.0045045045045045045]\n",
      "washington [0.9953271028037384, 0.004672897196261682]\n",
      "fl [0.9255813953488372, 0.07441860465116279]\n",
      "fortworth [0.8181818181818182, 0.18181818181818182]\n",
      "md [0.7464788732394366, 0.2535211267605634]\n",
      "de [0.9957446808510638, 0.00425531914893617]\n",
      "be [0.9956521739130435, 0.004347826086956522]\n",
      "berlin [0.993421052631579, 0.006578947368421052]\n",
      "ca [0.941970310391363, 0.058029689608636977]\n",
      "sanfrancisco [0.981203007518797, 0.018796992481203006]\n",
      "pensacola [0.8333333333333334, 0.16666666666666666]\n",
      "az [0.9886363636363636, 0.011363636363636364]\n",
      "phoenix [0.9772727272727273, 0.022727272727272728]\n",
      "nj [0.9830508474576272, 0.01694915254237288]\n",
      "jerseycity [0.9230769230769231, 0.07692307692307693]\n",
      "gb [0.992280701754386, 0.0077192982456140355]\n",
      "lnd [0.9950657894736842, 0.004934210526315789]\n",
      "london [0.9955947136563876, 0.004405286343612335]\n",
      "ct [0.9761904761904762, 0.023809523809523808]\n",
      "stamford [0.9285714285714286, 0.07142857142857142]\n",
      "orlando [0.8947368421052632, 0.10526315789473684]\n",
      "au [0.9489795918367347, 0.05102040816326531]\n",
      "nsw [0.96, 0.04]\n",
      "sydney [0.9375, 0.0625]\n",
      "sg [0.9777777777777777, 0.022222222222222223]\n",
      "01 [0.96, 0.04]\n",
      "singapore [0.9375, 0.0625]\n",
      "il [0.9724137931034482, 0.027586206896551724]\n",
      "telaviv [0.9523809523809523, 0.047619047619047616]\n",
      "israel [0.6666666666666666, 0.3333333333333333]\n",
      "sos [0.6666666666666666, 0.3333333333333333]\n",
      "southend-on-sea [0.6666666666666666, 0.3333333333333333]\n",
      "pa [0.9572192513368984, 0.0427807486631016]\n",
      "usanortheast [0.6666666666666666, 0.3333333333333333]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "locations_and_fraud_prob = compute_probabilities(locations_and_fraud_counts)\n",
    "    \n",
    "print('location [prob_location_fraud_false, prob_location_fraud_true]', '\\n')\n",
    "print_dictionary(locations_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### department feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique department with respect to the class lables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 unique departments: \n",
      " ['marketing' 'success' nan 'sales' 'androidpit' 'hr' 'r&d' 'engagement'\n",
      " 'businessfriend.com' 'medical' 'field' 'all' 'design' 'production' 'icm'\n",
      " 'general services' 'engineering' 'it' 'business development'\n",
      " 'human resources'] \n",
      "\n",
      "department [department_fraud_false, department_fraud_true] \n",
      "\n",
      "marketing [245, 1]\n",
      "success [4, 0]\n",
      "nan [6620, 258]\n",
      "sales [345, 9]\n",
      "androidpit [1, 0]\n",
      "hr [36, 3]\n",
      "r&d [23, 0]\n",
      "engagement [12, 0]\n",
      "businessfriend.com [1, 0]\n",
      "medical [6, 2]\n",
      "field [2, 0]\n",
      "all [11, 0]\n",
      "design [40, 0]\n",
      "production [18, 0]\n",
      "icm [1, 0]\n",
      "general services [1, 0]\n",
      "engineering [255, 45]\n",
      "it [158, 1]\n",
      "business development [21, 0]\n",
      "human resources [19, 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_departments = training_data['department'].str.lower()\n",
    "departments = np.array(training_data_departments.drop_duplicates())\n",
    "\n",
    "departments_and_fraud_counts = {}\n",
    "department_fraud_false = 0\n",
    "department_fraud_true = 0\n",
    "\n",
    "for j in range(20): # again we will consider only a small set of departments, 20 departments.\n",
    "        \n",
    "    for i in range(training_data['fraudulent'].shape[0]):\n",
    "\n",
    "        if str(training_data_departments[i]) == 'nan':\n",
    "\n",
    "            if str(departments[j]) == 'nan':\n",
    "\n",
    "                if training_data['fraudulent'].loc[i] == 0:\n",
    "                    department_fraud_false += 1\n",
    "                    \n",
    "                elif training_data['fraudulent'].loc[i] == 1:\n",
    "                    department_fraud_true += 1\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if str(departments[j]) != 'nan':\n",
    "\n",
    "                if training_data['fraudulent'].loc[i] == 0 and departments[j] == training_data_departments[i]:\n",
    "                    department_fraud_false += 1\n",
    "\n",
    "                elif training_data['fraudulent'].loc[i] == 1 and departments[j] == training_data_departments[i]:\n",
    "                    department_fraud_true += 1\n",
    "\n",
    "    departments_and_fraud_counts[departments[j]] = [department_fraud_false, department_fraud_true]   \n",
    "    department_fraud_false = 0\n",
    "    department_fraud_true = 0\n",
    "\n",
    "print('20 unique departments:', '\\n', departments[:20], '\\n')\n",
    "print('department [department_fraud_false, department_fraud_true]','\\n')\n",
    "print_dictionary(departments_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique department with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department [prob_department_fraud_false, prob_department_fraud_true] \n",
      "\n",
      "marketing [0.9959349593495935, 0.0040650406504065045]\n",
      "success [0.8333333333333334, 0.16666666666666666]\n",
      "nan [0.9624890956673452, 0.03751090433265484]\n",
      "sales [0.9745762711864406, 0.025423728813559324]\n",
      "androidpit [0.6666666666666666, 0.3333333333333333]\n",
      "hr [0.9230769230769231, 0.07692307692307693]\n",
      "r&d [0.96, 0.04]\n",
      "engagement [0.9285714285714286, 0.07142857142857142]\n",
      "businessfriend.com [0.6666666666666666, 0.3333333333333333]\n",
      "medical [0.75, 0.25]\n",
      "field [0.75, 0.25]\n",
      "all [0.9230769230769231, 0.07692307692307693]\n",
      "design [0.9761904761904762, 0.023809523809523808]\n",
      "production [0.95, 0.05]\n",
      "icm [0.6666666666666666, 0.3333333333333333]\n",
      "general services [0.6666666666666666, 0.3333333333333333]\n",
      "engineering [0.85, 0.15]\n",
      "it [0.9937106918238994, 0.006289308176100629]\n",
      "business development [0.9565217391304348, 0.043478260869565216]\n",
      "human resources [0.9047619047619048, 0.09523809523809523]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "departments_and_fraud_prob = compute_probabilities(departments_and_fraud_counts)\n",
    "    \n",
    "print('department [prob_department_fraud_false, prob_department_fraud_true]','\\n')\n",
    "print_dictionary(departments_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### salary_range feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique value in salary_range feature with respect to the class labes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 unique salary ranges: \n",
      " [nan '20000-28000' '100000-120000' '120000-150000' '50000-65000'\n",
      " '40000-50000' '60-80' '65000-70000' '75-115' '75000-110000' '17000-20000'\n",
      " '16000-28000' '95000-115000' '15000-18000' '50000-70000' '45000-60000'\n",
      " '30000-40000' '70000-90000' '10000-14000' '50-110'] \n",
      "\n",
      "salary range [salary_range_fraud_false, salary_range_fraud_true] \n",
      "\n",
      "nan [8698, 333]\n",
      "20000-28000 [1, 0]\n",
      "100000-120000 [9, 0]\n",
      "120000-150000 [5, 0]\n",
      "50000-65000 [12, 1]\n",
      "40000-50000 [50, 1]\n",
      "60-80 [1, 0]\n",
      "65000-70000 [6, 0]\n",
      "75-115 [1, 0]\n",
      "75000-110000 [2, 0]\n",
      "17000-20000 [3, 0]\n",
      "16000-28000 [1, 0]\n",
      "95000-115000 [1, 4]\n",
      "15000-18000 [3, 0]\n",
      "50000-70000 [19, 0]\n",
      "45000-60000 [11, 0]\n",
      "30000-40000 [30, 4]\n",
      "70000-90000 [26, 0]\n",
      "10000-14000 [2, 0]\n",
      "50-110 [1, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_salary_ranges = training_data['salary_range'].str.lower()\n",
    "salary_ranges = np.array(training_data_salary_ranges.drop_duplicates())\n",
    "\n",
    "salary_range_and_fraud_counts = {}\n",
    "salary_range_fraud_false = 0\n",
    "salary_range_fraud_true = 0\n",
    "\n",
    "for j in range(20): # again we will consider only a small set of salary ranges, 20 of them.\n",
    "        \n",
    "    for i in range(training_data['fraudulent'].shape[0]):\n",
    "\n",
    "        if str(training_data_salary_ranges[i]) == 'nan':\n",
    "\n",
    "            if str(salary_ranges[j]) == 'nan':\n",
    "\n",
    "                if training_data['fraudulent'].loc[i] == 0:\n",
    "                    salary_range_fraud_false += 1\n",
    "                    \n",
    "                elif training_data['fraudulent'].loc[i] == 1:\n",
    "                    salary_range_fraud_true += 1\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if str(salary_ranges[j]) != 'nan':\n",
    "\n",
    "                if training_data['fraudulent'].loc[i] == 0 and salary_ranges[j] == training_data_salary_ranges[i]:\n",
    "                    salary_range_fraud_false += 1\n",
    "\n",
    "                elif training_data['fraudulent'].loc[i] == 1 and salary_ranges[j] == training_data_salary_ranges[i]:\n",
    "                    salary_range_fraud_true += 1\n",
    "\n",
    "    salary_range_and_fraud_counts[salary_ranges[j]] = [salary_range_fraud_false, salary_range_fraud_true]\n",
    "    salary_range_fraud_false = 0\n",
    "    salary_range_fraud_true = 0\n",
    "\n",
    "print('20 unique salary ranges:', '\\n', salary_ranges[:20], '\\n')\n",
    "print('salary range [salary_range_fraud_false, salary_range_fraud_true]','\\n')\n",
    "print_dictionary(salary_range_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique salary range value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salary range [prob_salary_range_fraud_false, prob_salary_range_fraud_true] \n",
      "\n",
      "nan [0.9631270069759716, 0.03687299302402835]\n",
      "20000-28000 [0.6666666666666666, 0.3333333333333333]\n",
      "100000-120000 [0.9090909090909091, 0.09090909090909091]\n",
      "120000-150000 [0.8571428571428571, 0.14285714285714285]\n",
      "50000-65000 [0.9230769230769231, 0.07692307692307693]\n",
      "40000-50000 [0.9803921568627451, 0.0196078431372549]\n",
      "60-80 [0.6666666666666666, 0.3333333333333333]\n",
      "65000-70000 [0.875, 0.125]\n",
      "75-115 [0.6666666666666666, 0.3333333333333333]\n",
      "75000-110000 [0.75, 0.25]\n",
      "17000-20000 [0.8, 0.2]\n",
      "16000-28000 [0.6666666666666666, 0.3333333333333333]\n",
      "95000-115000 [0.2, 0.8]\n",
      "15000-18000 [0.8, 0.2]\n",
      "50000-70000 [0.9523809523809523, 0.047619047619047616]\n",
      "45000-60000 [0.9230769230769231, 0.07692307692307693]\n",
      "30000-40000 [0.8823529411764706, 0.11764705882352941]\n",
      "70000-90000 [0.9642857142857143, 0.03571428571428571]\n",
      "10000-14000 [0.75, 0.25]\n",
      "50-110 [0.6666666666666666, 0.3333333333333333]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "salary_range_and_fraud_prob = compute_probabilities(salary_range_and_fraud_counts)\n",
    "    \n",
    "print('salary range [prob_salary_range_fraud_false, prob_salary_range_fraud_true]','\\n')\n",
    "print_dictionary(salary_range_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### telecommuting feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique value in telecommuting feature with respect to the class labes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "telecommutings unique values:  [0 1] \n",
      "\n",
      "telecommuting [telecomuting_fraud_false, telecomuting_fraud_true] \n",
      "\n",
      "0 [9831, 421]\n",
      "1 [437, 40]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_telecommutings = training_data['telecommuting']\n",
    "telecommutings_unique = np.unique(training_data['telecommuting'])\n",
    "\n",
    "telecommutings_and_fraud_counts = compute_fraud_counts_binary_data(training_data['fraudulent'], training_data_telecommutings, telecommutings_unique)\n",
    "\n",
    "print('telecommutings unique values: ', telecommutings_unique, '\\n')\n",
    "print('telecommuting [telecomuting_fraud_false, telecomuting_fraud_true]','\\n')\n",
    "print_dictionary(telecommutings_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique telecommuting value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "telecommuting [prob_telecommuting_fraud_false, prob_telecommuting_fraud_true] \n",
      "\n",
      "0 [0.9589348419820523, 0.04106515801794772]\n",
      "1 [0.9161425576519916, 0.08385744234800839]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "telecommutings_and_fraud_prob = compute_probabilities(telecommutings_and_fraud_counts)\n",
    "    \n",
    "print('telecommuting [prob_telecommuting_fraud_false, prob_telecommuting_fraud_true]','\\n')\n",
    "print_dictionary(telecommutings_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_company_logo feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique value in has_company_logo feature with respect to the class labes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has company logo unique values:  [0 1] \n",
      "\n",
      "has_company_logo [has_company_logo_fraud_false, has_company_logo_fraud_true] \n",
      "\n",
      "0 [1873, 275]\n",
      "1 [8395, 186]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_has_company_logo = training_data['has_company_logo']\n",
    "has_company_logo_unique = np.unique(training_data['has_company_logo'])\n",
    "\n",
    "has_company_logo_and_fraud_counts = compute_fraud_counts_binary_data(training_data['fraudulent'], training_data_has_company_logo, has_company_logo_unique)\n",
    "\n",
    "print('has company logo unique values: ', has_company_logo_unique, '\\n')\n",
    "print('has_company_logo [has_company_logo_fraud_false, has_company_logo_fraud_true]', '\\n')\n",
    "print_dictionary(has_company_logo_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique has_company_logo feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_company_logo [prob_has_company_logo_fraud_false, prob_has_company_logo_fraud_true] \n",
      "\n",
      "0 [0.8719739292364991, 0.12802607076350092]\n",
      "1 [0.9783242046381541, 0.02167579536184594]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "has_company_logo_and_fraud_prob = compute_probabilities(has_company_logo_and_fraud_counts)\n",
    "    \n",
    "print('has_company_logo [prob_has_company_logo_fraud_false, prob_has_company_logo_fraud_true]', '\\n')\n",
    "print_dictionary(has_company_logo_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### has_questions feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique value in has_questions feature with respect to the class labes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has questions unique values:  [0 1] \n",
      "\n",
      "has_questions [has_questions_fraud_false, has_questions_fraud_true] \n",
      "\n",
      "0 [4702, 310]\n",
      "1 [5566, 151]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_has_questions = training_data['has_questions']\n",
    "has_questions_unique = np.unique(training_data['has_questions'])\n",
    "\n",
    "has_questions_and_fraud_counts = compute_fraud_counts_binary_data(training_data['fraudulent'], training_data_has_questions, has_questions_unique)\n",
    "\n",
    "print('has questions unique values: ', has_questions_unique, '\\n')\n",
    "print('has_questions [has_questions_fraud_false, has_questions_fraud_true]', '\\n')\n",
    "print_dictionary(has_questions_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique has_questions feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has_questions [prob_has_questions_fraud_false, prob_has_questions_fraud_true] \n",
      "\n",
      "0 [0.9381484437350359, 0.06185155626496409]\n",
      "1 [0.9735875459156901, 0.026412454084309953]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "has_questions_and_fraud_prob = compute_probabilities(has_questions_and_fraud_counts)\n",
    "    \n",
    "print('has_questions [prob_has_questions_fraud_false, prob_has_questions_fraud_true]', '\\n')\n",
    "print_dictionary(has_questions_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### employment_type feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique employment_type feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employment types unique values: \n",
      " ['other' 'full-time' nan 'part-time' 'contract' 'temporary'] \n",
      "\n",
      "employment_type [employment_type_fraud_false, employment_type_fraud_true] \n",
      "\n",
      "other [128, 4]\n",
      "full-time [6405, 289]\n",
      "nan [2098, 124]\n",
      "part-time [445, 17]\n",
      "contract [1040, 26]\n",
      "temporary [152, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_employment_types = training_data['employment_type'].str.lower()\n",
    "unique_employment_types = np.array(training_data_employment_types.drop_duplicates())\n",
    "\n",
    "employment_types_and_fraud_counts = compute_fraud_counts_feature(training_data['fraudulent'], training_data_employment_types, unique_employment_types)\n",
    "\n",
    "print('employment types unique values:', '\\n', unique_employment_types, '\\n')\n",
    "print('employment_type [employment_type_fraud_false, employment_type_fraud_true]', '\\n')\n",
    "print_dictionary(employment_types_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique employment_type feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employment_type [prob_employment_type_fraud_false, prob_employment_type_fraud_true] \n",
      "\n",
      "other [0.9696969696969697, 0.030303030303030304]\n",
      "full-time [0.9568270092620257, 0.04317299073797431]\n",
      "nan [0.9441944194419442, 0.0558055805580558]\n",
      "part-time [0.9632034632034632, 0.0367965367965368]\n",
      "contract [0.975609756097561, 0.024390243902439025]\n",
      "temporary [0.9934640522875817, 0.006535947712418301]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "employment_types_and_fraud_prob = compute_probabilities(employment_types_and_fraud_counts)\n",
    "    \n",
    "print('employment_type [prob_employment_type_fraud_false, prob_employment_type_fraud_true]', '\\n')\n",
    "print_dictionary(employment_types_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### required_experience feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique required_experience feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required experience unique values: \n",
      " ['internship' 'not applicable' nan 'mid-senior level' 'associate'\n",
      " 'entry level' 'executive' 'director'] \n",
      "\n",
      "required experience [required_experience_fraud_false, required_experience_fraud_true] \n",
      "\n",
      "internship [230, 6]\n",
      "not applicable [593, 21]\n",
      "nan [3987, 233]\n",
      "mid-senior level [2157, 67]\n",
      "associate [1379, 24]\n",
      "entry level [1610, 91]\n",
      "executive [80, 8]\n",
      "director [232, 11]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_required_experience = training_data['required_experience'].str.lower()\n",
    "required_experience_unique = np.array(training_data_required_experience.drop_duplicates())\n",
    "\n",
    "required_experience_and_fraud_counts = compute_fraud_counts_feature(training_data['fraudulent'], training_data_required_experience, required_experience_unique)\n",
    "\n",
    "print('required experience unique values:', '\\n', required_experience_unique, '\\n')\n",
    "print('required experience [required_experience_fraud_false, required_experience_fraud_true]', '\\n')\n",
    "print_dictionary(required_experience_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique required_experience feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_experience [prob_required_experience_fraud_false, prob_required_experience_fraud_true] \n",
      "\n",
      "internship [0.9745762711864406, 0.025423728813559324]\n",
      "not applicable [0.9657980456026058, 0.03420195439739414]\n",
      "nan [0.9447867298578199, 0.055213270142180096]\n",
      "mid-senior level [0.9698741007194245, 0.03012589928057554]\n",
      "associate [0.9828937990021382, 0.017106200997861726]\n",
      "entry level [0.9465020576131687, 0.053497942386831275]\n",
      "executive [0.9090909090909091, 0.09090909090909091]\n",
      "director [0.9547325102880658, 0.04526748971193416]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "required_experience_and_fraud_prob = compute_probabilities(required_experience_and_fraud_counts)\n",
    "    \n",
    "print('required_experience [prob_required_experience_fraud_false, prob_required_experience_fraud_true]', '\\n')\n",
    "print_dictionary(required_experience_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### required_education feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique required_education feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required education unique values: \n",
      " [nan \"bachelor's degree\" \"master's degree\" 'high school or equivalent'\n",
      " 'unspecified' 'some college coursework completed' 'vocational'\n",
      " 'certification' 'associate degree' 'professional' 'doctorate'\n",
      " 'some high school coursework' 'vocational - degree'\n",
      " 'vocational - hs diploma'] \n",
      "\n",
      "required education [required_education_fraud_false, required_education_fraud_true] \n",
      "\n",
      "nan [4434, 221]\n",
      "bachelor's degree [3192, 62]\n",
      "master's degree [240, 21]\n",
      "high school or equivalent [1158, 98]\n",
      "unspecified [853, 25]\n",
      "some college coursework completed [66, 1]\n",
      "vocational [24, 0]\n",
      "certification [80, 11]\n",
      "associate degree [148, 5]\n",
      "professional [39, 3]\n",
      "doctorate [20, 0]\n",
      "some high school coursework [6, 14]\n",
      "vocational - degree [5, 0]\n",
      "vocational - hs diploma [3, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_required_education = training_data['required_education'].str.lower()\n",
    "required_education_unique = np.array(training_data_required_education.drop_duplicates())\n",
    "\n",
    "required_education_and_fraud_counts = compute_fraud_counts_feature(training_data['fraudulent'], training_data_required_education, required_education_unique)\n",
    "\n",
    "print('required education unique values:', '\\n', required_education_unique, '\\n')\n",
    "print('required education [required_education_fraud_false, required_education_fraud_true]','\\n')\n",
    "print_dictionary(required_education_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique required_education feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_education [prob_required_education_fraud_false, prob_required_education_fraud_true] \n",
      "\n",
      "nan [0.9525241675617615, 0.047475832438238455]\n",
      "bachelor's degree [0.9809465273509527, 0.019053472649047325]\n",
      "master's degree [0.9195402298850575, 0.08045977011494253]\n",
      "high school or equivalent [0.9219745222929936, 0.07802547770700637]\n",
      "unspecified [0.9715261958997722, 0.02847380410022779]\n",
      "some college coursework completed [0.9850746268656716, 0.014925373134328358]\n",
      "vocational [0.9615384615384616, 0.038461538461538464]\n",
      "certification [0.8791208791208791, 0.12087912087912088]\n",
      "associate degree [0.9673202614379085, 0.032679738562091505]\n",
      "professional [0.9285714285714286, 0.07142857142857142]\n",
      "doctorate [0.9545454545454546, 0.045454545454545456]\n",
      "some high school coursework [0.3, 0.7]\n",
      "vocational - degree [0.8571428571428571, 0.14285714285714285]\n",
      "vocational - hs diploma [0.8, 0.2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "required_education_and_fraud_prob = compute_probabilities(required_education_and_fraud_counts)\n",
    "    \n",
    "print('required_education [prob_required_education_fraud_false, prob_required_education_fraud_true]','\\n')\n",
    "print_dictionary(required_education_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### industry feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique industry feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industries unique: \n",
      " [nan 'marketing and advertising' 'computer software'\n",
      " 'hospital & health care' 'online media'\n",
      " 'information technology and services' 'financial services'\n",
      " 'management consulting' 'events services' 'internet'\n",
      " 'facilities services' 'consumer electronics' 'telecommunications'\n",
      " 'consumer services' 'construction' 'oil & energy' 'education management'\n",
      " 'building materials' 'banking' 'food & beverages' 'food production'\n",
      " 'health, wellness and fitness' 'insurance' 'e-learning' 'cosmetics'\n",
      " 'staffing and recruiting' 'venture capital & private equity'\n",
      " 'leisure, travel & tourism' 'human resources' 'pharmaceuticals' 'farming'\n",
      " 'legal services' 'luxury goods & jewelry' 'machinery' 'real estate'\n",
      " 'mechanical or industrial engineering'\n",
      " 'public relations and communications' 'consumer goods' 'medical practice'\n",
      " 'electrical/electronic manufacturing' 'hospitality' 'music'\n",
      " 'market research' 'automotive' 'philanthropy' 'utilities'\n",
      " 'primary/secondary education' 'logistics and supply chain' 'design'\n",
      " 'gambling & casinos' 'accounting' 'environmental services'\n",
      " 'mental health care' 'investment management' 'apparel & fashion'\n",
      " 'media production' 'publishing' 'medical devices' 'information services'\n",
      " 'retail' 'sports' 'computer games' 'chemicals' 'aviation & aerospace'\n",
      " 'business supplies and equipment' 'program development'\n",
      " 'computer networking' 'biotechnology' 'civic & social organization'\n",
      " 'religious institutions' 'warehousing' 'airlines/aviation'\n",
      " 'writing and editing' 'restaurants' 'outsourcing/offshoring'\n",
      " 'transportation/trucking/railroad' 'wireless' 'investment banking'\n",
      " 'nonprofit organization management' 'libraries' 'computer hardware'\n",
      " 'broadcast media' 'printing' 'graphic design' 'entertainment' 'wholesale'\n",
      " 'research' 'animation' 'government administration' 'capital markets'\n",
      " 'computer & network security' 'semiconductors'\n",
      " 'security and investigations' 'architecture & planning' 'maritime'\n",
      " 'fund-raising' 'higher education' 'renewables & environment'\n",
      " 'motion pictures and film' 'law practice' 'government relations'\n",
      " 'packaging and containers' 'sporting goods' 'mining & metals'\n",
      " 'import and export' 'international trade and development'\n",
      " 'professional training & coaching' 'textiles' 'commercial real estate'\n",
      " 'law enforcement' 'package/freight delivery'\n",
      " 'translation and localization' 'photography' 'industrial automation'\n",
      " 'wine and spirits' 'public safety' 'civil engineering' 'military'\n",
      " 'defense & space' 'veterinary' 'executive office' 'performing arts'\n",
      " 'individual & family services' 'public policy' 'nanotechnology'] \n",
      "\n",
      "industry [industry_fraud_false, industry_fraud_true] \n",
      "\n",
      "nan [2845, 116]\n",
      "marketing and advertising [466, 25]\n",
      "computer software [813, 3]\n",
      "hospital & health care [285, 30]\n",
      "online media [66, 0]\n",
      "information technology and services [937, 15]\n",
      "financial services [513, 20]\n",
      "management consulting [67, 5]\n",
      "events services [33, 0]\n",
      "internet [613, 0]\n",
      "facilities services [57, 0]\n",
      "consumer electronics [37, 0]\n",
      "telecommunications [195, 14]\n",
      "consumer services [179, 9]\n",
      "construction [94, 3]\n",
      "oil & energy [128, 89]\n",
      "education management [621, 0]\n",
      "building materials [53, 0]\n",
      "banking [49, 1]\n",
      "food & beverages [43, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_industry = training_data['industry'].str.lower()\n",
    "industries_unique = np.array(training_data_industry.drop_duplicates())\n",
    "\n",
    "industries_and_fraud_counts = {}\n",
    "industry_fraud_false = 0\n",
    "industry_fraud_true = 0\n",
    "\n",
    "# again we will consider only a small set of industries, 20 industries.\n",
    "for j in range(20):\n",
    "        \n",
    "    for i in range(training_data['fraudulent'].shape[0]):\n",
    "\n",
    "        if str(training_data_industry[i]) == 'nan':\n",
    "\n",
    "            if str(industries_unique[j]) == 'nan':\n",
    "\n",
    "                if training_data['fraudulent'].loc[i] == 0:\n",
    "                    industry_fraud_false += 1\n",
    "                elif training_data['fraudulent'].loc[i] == 1:\n",
    "                    industry_fraud_true += 1\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if str(industries_unique[j]) != 'nan':\n",
    "\n",
    "                if training_data['fraudulent'].loc[i] == 0 and industries_unique[j] == training_data_industry[i]:\n",
    "                    industry_fraud_false += 1\n",
    "\n",
    "                elif training_data['fraudulent'].loc[i] == 1 and industries_unique[j] == training_data_industry[i]:\n",
    "                    industry_fraud_true += 1\n",
    "\n",
    "    industries_and_fraud_counts[industries_unique[j]] = [industry_fraud_false, industry_fraud_true]\n",
    "    industry_fraud_false = 0\n",
    "    industry_fraud_true = 0\n",
    "\n",
    "print('industries unique:', '\\n', industries_unique, '\\n')\n",
    "print('industry [industry_fraud_false, industry_fraud_true]','\\n')\n",
    "print_dictionary(industries_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique industry feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry [prob_industry_fraud_false, prob_industry_fraud_true] \n",
      "\n",
      "nan [0.9608240459304289, 0.03917595406957109]\n",
      "marketing and advertising [0.9490835030549898, 0.05091649694501019]\n",
      "computer software [0.9963235294117647, 0.003676470588235294]\n",
      "hospital & health care [0.9047619047619048, 0.09523809523809523]\n",
      "online media [0.9852941176470589, 0.014705882352941176]\n",
      "information technology and services [0.9842436974789915, 0.015756302521008403]\n",
      "financial services [0.9624765478424016, 0.0375234521575985]\n",
      "management consulting [0.9305555555555556, 0.06944444444444445]\n",
      "events services [0.9714285714285714, 0.02857142857142857]\n",
      "internet [0.9983739837398374, 0.0016260162601626016]\n",
      "facilities services [0.9830508474576272, 0.01694915254237288]\n",
      "consumer electronics [0.9743589743589743, 0.02564102564102564]\n",
      "telecommunications [0.9330143540669856, 0.06698564593301436]\n",
      "consumer services [0.9521276595744681, 0.047872340425531915]\n",
      "construction [0.9690721649484536, 0.030927835051546393]\n",
      "oil & energy [0.5898617511520737, 0.41013824884792627]\n",
      "education management [0.9983948635634029, 0.0016051364365971107]\n",
      "building materials [0.9818181818181818, 0.01818181818181818]\n",
      "banking [0.98, 0.02]\n",
      "food & beverages [0.9777777777777777, 0.022222222222222223]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "industries_and_fraud_prob = compute_probabilities(industries_and_fraud_counts)\n",
    "    \n",
    "print('industry [prob_industry_fraud_false, prob_industry_fraud_true]','\\n')\n",
    "print_dictionary(industries_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute fraud counts of each unique function feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function unique values: \n",
      " ['marketing' 'customer service' nan 'sales' 'health care provider'\n",
      " 'management' 'information technology' 'other' 'engineering'\n",
      " 'administrative' 'design' 'production' 'education' 'supply chain'\n",
      " 'business development' 'product management' 'financial analyst'\n",
      " 'consulting' 'human resources' 'project management' 'manufacturing'\n",
      " 'public relations' 'strategy/planning' 'advertising' 'finance'\n",
      " 'general business' 'research' 'accounting/auditing' 'art/creative'\n",
      " 'quality assurance' 'data analyst' 'business analyst' 'writing/editing'\n",
      " 'distribution' 'science' 'training' 'purchasing' 'legal'] \n",
      "\n",
      "function [function_fraud_false, function_fraud_true] \n",
      "\n",
      "marketing [479, 4]\n",
      "customer service [657, 41]\n",
      "nan [3652, 155]\n",
      "sales [854, 22]\n",
      "health care provider [207, 0]\n",
      "management [203, 6]\n",
      "information technology [1036, 14]\n",
      "other [184, 21]\n",
      "engineering [681, 90]\n",
      "administrative [347, 51]\n",
      "design [191, 1]\n",
      "production [68, 0]\n",
      "education [281, 1]\n",
      "supply chain [16, 0]\n",
      "business development [147, 4]\n",
      "product management [70, 0]\n",
      "financial analyst [14, 3]\n",
      "consulting [86, 3]\n",
      "human resources [117, 6]\n",
      "project management [104, 8]\n",
      "manufacturing [43, 2]\n",
      "public relations [47, 1]\n",
      "strategy/planning [28, 1]\n",
      "advertising [59, 3]\n",
      "finance [101, 11]\n",
      "general business [45, 0]\n",
      "research [23, 0]\n",
      "accounting/auditing [130, 8]\n",
      "art/creative [72, 0]\n",
      "quality assurance [73, 0]\n",
      "data analyst [52, 1]\n",
      "business analyst [45, 1]\n",
      "writing/editing [81, 0]\n",
      "distribution [10, 3]\n",
      "science [5, 0]\n",
      "training [24, 0]\n",
      "purchasing [6, 0]\n",
      "legal [30, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_data_function = training_data['function'].str.lower()\n",
    "functions_unique = np.array(training_data_function.drop_duplicates())\n",
    "\n",
    "functions_and_fraud_counts = compute_fraud_counts_feature(training_data['fraudulent'], training_data_function, functions_unique)\n",
    "\n",
    "print('function unique values:', '\\n', functions_unique, '\\n')\n",
    "print('function [function_fraud_false, function_fraud_true]','\\n')\n",
    "print_dictionary(functions_and_fraud_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute probabilities of each unique function feature value with respect to the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function [prob_function_fraud_false, prob_function_fraud_true] \n",
      "\n",
      "marketing [0.9917184265010351, 0.008281573498964804]\n",
      "customer service [0.9412607449856734, 0.05873925501432665]\n",
      "nan [0.9592855266614132, 0.04071447333858681]\n",
      "sales [0.9748858447488584, 0.02511415525114155]\n",
      "health care provider [0.9952153110047847, 0.004784688995215311]\n",
      "management [0.9712918660287081, 0.028708133971291867]\n",
      "information technology [0.9866666666666667, 0.013333333333333334]\n",
      "other [0.8975609756097561, 0.1024390243902439]\n",
      "engineering [0.8832684824902723, 0.11673151750972763]\n",
      "administrative [0.871859296482412, 0.12814070351758794]\n",
      "design [0.9947916666666666, 0.005208333333333333]\n",
      "production [0.9857142857142858, 0.014285714285714285]\n",
      "education [0.9964539007092199, 0.0035460992907801418]\n",
      "supply chain [0.9444444444444444, 0.05555555555555555]\n",
      "business development [0.9735099337748344, 0.026490066225165563]\n",
      "product management [0.9861111111111112, 0.013888888888888888]\n",
      "financial analyst [0.8235294117647058, 0.17647058823529413]\n",
      "consulting [0.9662921348314607, 0.033707865168539325]\n",
      "human resources [0.9512195121951219, 0.04878048780487805]\n",
      "project management [0.9285714285714286, 0.07142857142857142]\n",
      "manufacturing [0.9555555555555556, 0.044444444444444446]\n",
      "public relations [0.9791666666666666, 0.020833333333333332]\n",
      "strategy/planning [0.9655172413793104, 0.034482758620689655]\n",
      "advertising [0.9516129032258065, 0.04838709677419355]\n",
      "finance [0.9017857142857143, 0.09821428571428571]\n",
      "general business [0.9787234042553191, 0.02127659574468085]\n",
      "research [0.96, 0.04]\n",
      "accounting/auditing [0.9420289855072463, 0.057971014492753624]\n",
      "art/creative [0.9864864864864865, 0.013513513513513514]\n",
      "quality assurance [0.9866666666666667, 0.013333333333333334]\n",
      "data analyst [0.9811320754716981, 0.018867924528301886]\n",
      "business analyst [0.9782608695652174, 0.021739130434782608]\n",
      "writing/editing [0.9879518072289156, 0.012048192771084338]\n",
      "distribution [0.7692307692307693, 0.23076923076923078]\n",
      "science [0.8571428571428571, 0.14285714285714285]\n",
      "training [0.9615384615384616, 0.038461538461538464]\n",
      "purchasing [0.875, 0.125]\n",
      "legal [0.96875, 0.03125]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "functions_and_fraud_prob = compute_probabilities(functions_and_fraud_counts)\n",
    "    \n",
    "print('function [prob_function_fraud_false, prob_function_fraud_true]','\\n')\n",
    "print_dictionary(functions_and_fraud_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected features and unique feature values with their probabilities for each class label: \n",
      "\n",
      "title\n",
      "marketing intern [0.9230769230769231, 0.07692307692307693]\n",
      "customer service - cloud video production [0.6666666666666666, 0.3333333333333333]\n",
      "commissioning machinery assistant (cma) [0.6666666666666666, 0.3333333333333333]\n",
      "account executive - washington dc [0.6666666666666666, 0.3333333333333333]\n",
      "bill review manager [0.6666666666666666, 0.3333333333333333]\n",
      "accounting clerk [0.5, 0.5]\n",
      "head of content (m/f) [0.6666666666666666, 0.3333333333333333]\n",
      "lead guest service specialist [0.6666666666666666, 0.3333333333333333]\n",
      "hp bsm sme [0.75, 0.25]\n",
      "customer service associate - part time [0.9848484848484849, 0.015151515151515152]\n",
      "asp.net developer job opportunity at united states,new jersey [0.6666666666666666, 0.3333333333333333]\n",
      "talent sourcer (6 months fixed-term contract) [0.6666666666666666, 0.3333333333333333]\n",
      "applications developer, digital [0.6666666666666666, 0.3333333333333333]\n",
      "installers [0.75, 0.25]\n",
      "account executive - sydney [0.6666666666666666, 0.3333333333333333]\n",
      "vp of sales - vault dragon [0.6666666666666666, 0.3333333333333333]\n",
      "hands-on qa leader [0.6666666666666666, 0.3333333333333333]\n",
      "southend-on-sea traineeships under nas 16-18 year olds only [0.6666666666666666, 0.3333333333333333]\n",
      "visual designer [0.875, 0.125]\n",
      "process controls engineer - dcs plc ms office - pa [0.6666666666666666, 0.3333333333333333]\n",
      "marketing assistant [0.9, 0.1]\n",
      "front end developer [0.9642857142857143, 0.03571428571428571]\n",
      "engagement manager [0.8333333333333334, 0.16666666666666666]\n",
      "vice president, sales and sponsorship (businessfriend.com) [0.6666666666666666, 0.3333333333333333]\n",
      "customer service [0.75, 0.25]\n",
      "h1b sponsor for l1/l2/opt [0.75, 0.25]\n",
      "marketing exec [0.75, 0.25]\n",
      "haad/dha licensed doctors opening in uae [0.6666666666666666, 0.3333333333333333]\n",
      "talent management process manager [0.875, 0.125]\n",
      "customer service associate [0.9927007299270073, 0.0072992700729927005]\n",
      "customer service technical specialist [0.96, 0.04]\n",
      "software applications specialist [0.6666666666666666, 0.3333333333333333]\n",
      "craftsman associate [0.6666666666666666, 0.3333333333333333]\n",
      "completion engineer [0.8333333333333334, 0.16666666666666666]\n",
      "i want to work at karmarama [0.6666666666666666, 0.3333333333333333]\n",
      "english teacher abroad [0.9962406015037594, 0.0037593984962406013]\n",
      "graduates: english teacher abroad [0.9814814814814815, 0.018518518518518517]\n",
      "project manager [0.9736842105263158, 0.02631578947368421]\n",
      "art director [0.8571428571428571, 0.14285714285714285]\n",
      "receptionist/customer service technical specialist [0.6666666666666666, 0.3333333333333333]\n",
      "jr. developer [0.75, 0.25]\n",
      "customer service associate receptionist [0.6666666666666666, 0.3333333333333333]\n",
      "customer service team lead [0.975, 0.025]\n",
      "inside sales professional-omaha [0.8, 0.2]\n",
      "entry level [0.6666666666666666, 0.3333333333333333]\n",
      "food production manager @ pgi, a food production company [0.6666666666666666, 0.3333333333333333]\n",
      "administrative/front desk [0.6666666666666666, 0.3333333333333333]\n",
      "payroll tax specialist [0.6666666666666666, 0.3333333333333333]\n",
      "technical project manager [0.9090909090909091, 0.09090909090909091]\n",
      "outside sales professional-st. cloud [0.6666666666666666, 0.3333333333333333]\n",
      "\n",
      "location\n",
      "us [0.9354632587859425, 0.0645367412140575]\n",
      "ny [0.95822454308094, 0.04177545691906005]\n",
      "newyork [0.9880382775119617, 0.011961722488038277]\n",
      "nz [0.995, 0.005]\n",
      "auckland [0.993103448275862, 0.006896551724137931]\n",
      "ia [0.9574468085106383, 0.0425531914893617]\n",
      "wever [0.6666666666666666, 0.3333333333333333]\n",
      "dc [0.9954954954954955, 0.0045045045045045045]\n",
      "washington [0.9953271028037384, 0.004672897196261682]\n",
      "fl [0.9255813953488372, 0.07441860465116279]\n",
      "fortworth [0.8181818181818182, 0.18181818181818182]\n",
      "md [0.7464788732394366, 0.2535211267605634]\n",
      "de [0.9957446808510638, 0.00425531914893617]\n",
      "be [0.9956521739130435, 0.004347826086956522]\n",
      "berlin [0.993421052631579, 0.006578947368421052]\n",
      "ca [0.941970310391363, 0.058029689608636977]\n",
      "sanfrancisco [0.981203007518797, 0.018796992481203006]\n",
      "pensacola [0.8333333333333334, 0.16666666666666666]\n",
      "az [0.9886363636363636, 0.011363636363636364]\n",
      "phoenix [0.9772727272727273, 0.022727272727272728]\n",
      "nj [0.9830508474576272, 0.01694915254237288]\n",
      "jerseycity [0.9230769230769231, 0.07692307692307693]\n",
      "gb [0.992280701754386, 0.0077192982456140355]\n",
      "lnd [0.9950657894736842, 0.004934210526315789]\n",
      "london [0.9955947136563876, 0.004405286343612335]\n",
      "ct [0.9761904761904762, 0.023809523809523808]\n",
      "stamford [0.9285714285714286, 0.07142857142857142]\n",
      "orlando [0.8947368421052632, 0.10526315789473684]\n",
      "au [0.9489795918367347, 0.05102040816326531]\n",
      "nsw [0.96, 0.04]\n",
      "sydney [0.9375, 0.0625]\n",
      "sg [0.9777777777777777, 0.022222222222222223]\n",
      "01 [0.96, 0.04]\n",
      "singapore [0.9375, 0.0625]\n",
      "il [0.9724137931034482, 0.027586206896551724]\n",
      "telaviv [0.9523809523809523, 0.047619047619047616]\n",
      "israel [0.6666666666666666, 0.3333333333333333]\n",
      "sos [0.6666666666666666, 0.3333333333333333]\n",
      "southend-on-sea [0.6666666666666666, 0.3333333333333333]\n",
      "pa [0.9572192513368984, 0.0427807486631016]\n",
      "usanortheast [0.6666666666666666, 0.3333333333333333]\n",
      "\n",
      "department\n",
      "marketing [0.9959349593495935, 0.0040650406504065045]\n",
      "success [0.8333333333333334, 0.16666666666666666]\n",
      "nan [0.9624890956673452, 0.03751090433265484]\n",
      "sales [0.9745762711864406, 0.025423728813559324]\n",
      "androidpit [0.6666666666666666, 0.3333333333333333]\n",
      "hr [0.9230769230769231, 0.07692307692307693]\n",
      "r&d [0.96, 0.04]\n",
      "engagement [0.9285714285714286, 0.07142857142857142]\n",
      "businessfriend.com [0.6666666666666666, 0.3333333333333333]\n",
      "medical [0.75, 0.25]\n",
      "field [0.75, 0.25]\n",
      "all [0.9230769230769231, 0.07692307692307693]\n",
      "design [0.9761904761904762, 0.023809523809523808]\n",
      "production [0.95, 0.05]\n",
      "icm [0.6666666666666666, 0.3333333333333333]\n",
      "general services [0.6666666666666666, 0.3333333333333333]\n",
      "engineering [0.85, 0.15]\n",
      "it [0.9937106918238994, 0.006289308176100629]\n",
      "business development [0.9565217391304348, 0.043478260869565216]\n",
      "human resources [0.9047619047619048, 0.09523809523809523]\n",
      "\n",
      "salary_range\n",
      "nan [0.9631270069759716, 0.03687299302402835]\n",
      "20000-28000 [0.6666666666666666, 0.3333333333333333]\n",
      "100000-120000 [0.9090909090909091, 0.09090909090909091]\n",
      "120000-150000 [0.8571428571428571, 0.14285714285714285]\n",
      "50000-65000 [0.9230769230769231, 0.07692307692307693]\n",
      "40000-50000 [0.9803921568627451, 0.0196078431372549]\n",
      "60-80 [0.6666666666666666, 0.3333333333333333]\n",
      "65000-70000 [0.875, 0.125]\n",
      "75-115 [0.6666666666666666, 0.3333333333333333]\n",
      "75000-110000 [0.75, 0.25]\n",
      "17000-20000 [0.8, 0.2]\n",
      "16000-28000 [0.6666666666666666, 0.3333333333333333]\n",
      "95000-115000 [0.2, 0.8]\n",
      "15000-18000 [0.8, 0.2]\n",
      "50000-70000 [0.9523809523809523, 0.047619047619047616]\n",
      "45000-60000 [0.9230769230769231, 0.07692307692307693]\n",
      "30000-40000 [0.8823529411764706, 0.11764705882352941]\n",
      "70000-90000 [0.9642857142857143, 0.03571428571428571]\n",
      "10000-14000 [0.75, 0.25]\n",
      "50-110 [0.6666666666666666, 0.3333333333333333]\n",
      "\n",
      "telecommuting\n",
      "0 [0.9589348419820523, 0.04106515801794772]\n",
      "1 [0.9161425576519916, 0.08385744234800839]\n",
      "\n",
      "has_company_logo\n",
      "0 [0.8719739292364991, 0.12802607076350092]\n",
      "1 [0.9783242046381541, 0.02167579536184594]\n",
      "\n",
      "has_questions\n",
      "0 [0.9381484437350359, 0.06185155626496409]\n",
      "1 [0.9735875459156901, 0.026412454084309953]\n",
      "\n",
      "employment_type\n",
      "other [0.9696969696969697, 0.030303030303030304]\n",
      "full-time [0.9568270092620257, 0.04317299073797431]\n",
      "nan [0.9441944194419442, 0.0558055805580558]\n",
      "part-time [0.9632034632034632, 0.0367965367965368]\n",
      "contract [0.975609756097561, 0.024390243902439025]\n",
      "temporary [0.9934640522875817, 0.006535947712418301]\n",
      "\n",
      "required_experience\n",
      "internship [0.9745762711864406, 0.025423728813559324]\n",
      "not applicable [0.9657980456026058, 0.03420195439739414]\n",
      "nan [0.9447867298578199, 0.055213270142180096]\n",
      "mid-senior level [0.9698741007194245, 0.03012589928057554]\n",
      "associate [0.9828937990021382, 0.017106200997861726]\n",
      "entry level [0.9465020576131687, 0.053497942386831275]\n",
      "executive [0.9090909090909091, 0.09090909090909091]\n",
      "director [0.9547325102880658, 0.04526748971193416]\n",
      "\n",
      "required_education\n",
      "nan [0.9525241675617615, 0.047475832438238455]\n",
      "bachelor's degree [0.9809465273509527, 0.019053472649047325]\n",
      "master's degree [0.9195402298850575, 0.08045977011494253]\n",
      "high school or equivalent [0.9219745222929936, 0.07802547770700637]\n",
      "unspecified [0.9715261958997722, 0.02847380410022779]\n",
      "some college coursework completed [0.9850746268656716, 0.014925373134328358]\n",
      "vocational [0.9615384615384616, 0.038461538461538464]\n",
      "certification [0.8791208791208791, 0.12087912087912088]\n",
      "associate degree [0.9673202614379085, 0.032679738562091505]\n",
      "professional [0.9285714285714286, 0.07142857142857142]\n",
      "doctorate [0.9545454545454546, 0.045454545454545456]\n",
      "some high school coursework [0.3, 0.7]\n",
      "vocational - degree [0.8571428571428571, 0.14285714285714285]\n",
      "vocational - hs diploma [0.8, 0.2]\n",
      "\n",
      "industry\n",
      "nan [0.9608240459304289, 0.03917595406957109]\n",
      "marketing and advertising [0.9490835030549898, 0.05091649694501019]\n",
      "computer software [0.9963235294117647, 0.003676470588235294]\n",
      "hospital & health care [0.9047619047619048, 0.09523809523809523]\n",
      "online media [0.9852941176470589, 0.014705882352941176]\n",
      "information technology and services [0.9842436974789915, 0.015756302521008403]\n",
      "financial services [0.9624765478424016, 0.0375234521575985]\n",
      "management consulting [0.9305555555555556, 0.06944444444444445]\n",
      "events services [0.9714285714285714, 0.02857142857142857]\n",
      "internet [0.9983739837398374, 0.0016260162601626016]\n",
      "facilities services [0.9830508474576272, 0.01694915254237288]\n",
      "consumer electronics [0.9743589743589743, 0.02564102564102564]\n",
      "telecommunications [0.9330143540669856, 0.06698564593301436]\n",
      "consumer services [0.9521276595744681, 0.047872340425531915]\n",
      "construction [0.9690721649484536, 0.030927835051546393]\n",
      "oil & energy [0.5898617511520737, 0.41013824884792627]\n",
      "education management [0.9983948635634029, 0.0016051364365971107]\n",
      "building materials [0.9818181818181818, 0.01818181818181818]\n",
      "banking [0.98, 0.02]\n",
      "food & beverages [0.9777777777777777, 0.022222222222222223]\n",
      "\n",
      "function\n",
      "marketing [0.9917184265010351, 0.008281573498964804]\n",
      "customer service [0.9412607449856734, 0.05873925501432665]\n",
      "nan [0.9592855266614132, 0.04071447333858681]\n",
      "sales [0.9748858447488584, 0.02511415525114155]\n",
      "health care provider [0.9952153110047847, 0.004784688995215311]\n",
      "management [0.9712918660287081, 0.028708133971291867]\n",
      "information technology [0.9866666666666667, 0.013333333333333334]\n",
      "other [0.8975609756097561, 0.1024390243902439]\n",
      "engineering [0.8832684824902723, 0.11673151750972763]\n",
      "administrative [0.871859296482412, 0.12814070351758794]\n",
      "design [0.9947916666666666, 0.005208333333333333]\n",
      "production [0.9857142857142858, 0.014285714285714285]\n",
      "education [0.9964539007092199, 0.0035460992907801418]\n",
      "supply chain [0.9444444444444444, 0.05555555555555555]\n",
      "business development [0.9735099337748344, 0.026490066225165563]\n",
      "product management [0.9861111111111112, 0.013888888888888888]\n",
      "financial analyst [0.8235294117647058, 0.17647058823529413]\n",
      "consulting [0.9662921348314607, 0.033707865168539325]\n",
      "human resources [0.9512195121951219, 0.04878048780487805]\n",
      "project management [0.9285714285714286, 0.07142857142857142]\n",
      "manufacturing [0.9555555555555556, 0.044444444444444446]\n",
      "public relations [0.9791666666666666, 0.020833333333333332]\n",
      "strategy/planning [0.9655172413793104, 0.034482758620689655]\n",
      "advertising [0.9516129032258065, 0.04838709677419355]\n",
      "finance [0.9017857142857143, 0.09821428571428571]\n",
      "general business [0.9787234042553191, 0.02127659574468085]\n",
      "research [0.96, 0.04]\n",
      "accounting/auditing [0.9420289855072463, 0.057971014492753624]\n",
      "art/creative [0.9864864864864865, 0.013513513513513514]\n",
      "quality assurance [0.9866666666666667, 0.013333333333333334]\n",
      "data analyst [0.9811320754716981, 0.018867924528301886]\n",
      "business analyst [0.9782608695652174, 0.021739130434782608]\n",
      "writing/editing [0.9879518072289156, 0.012048192771084338]\n",
      "distribution [0.7692307692307693, 0.23076923076923078]\n",
      "science [0.8571428571428571, 0.14285714285714285]\n",
      "training [0.9615384615384616, 0.038461538461538464]\n",
      "purchasing [0.875, 0.125]\n",
      "legal [0.96875, 0.03125]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_values_prob = []\n",
    "feature_values_prob.append(titles_and_fraud_prob)\n",
    "feature_values_prob.append(locations_and_fraud_prob)\n",
    "feature_values_prob.append(departments_and_fraud_prob)\n",
    "feature_values_prob.append(salary_range_and_fraud_prob)\n",
    "feature_values_prob.append(telecommutings_and_fraud_prob)\n",
    "feature_values_prob.append(has_company_logo_and_fraud_prob)\n",
    "feature_values_prob.append(has_questions_and_fraud_prob)\n",
    "feature_values_prob.append(employment_types_and_fraud_prob)\n",
    "feature_values_prob.append(required_experience_and_fraud_prob)\n",
    "feature_values_prob.append(required_education_and_fraud_prob)\n",
    "feature_values_prob.append(industries_and_fraud_prob)\n",
    "feature_values_prob.append(functions_and_fraud_prob)\n",
    "\n",
    "selected_features = []\n",
    "for i in range(features.shape[0]):\n",
    "    if i not in range(4,8) and i != features.shape[0]:\n",
    "        selected_features.append(features[i])\n",
    "\n",
    "data = {}\n",
    "for i in range(len(feature_values_prob)):\n",
    "    data[selected_features[i]] = feature_values_prob[i]\n",
    "\n",
    "print('selected features and unique feature values with their probabilities for each class label:','\\n')\n",
    "for key,value in data.items():\n",
    "    print(key)\n",
    "    print_dictionary(value)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_job_postings(dataset):\n",
    "    \n",
    "    datapoint_prob_0 = []\n",
    "    datapoint_prob_1 = []\n",
    "    bayes_numerator = []\n",
    "    \n",
    "    job_ids = dataset['job_id'].to_numpy()\n",
    "    i = job_ids[0]-1\n",
    "    \n",
    "    # for each data point\n",
    "    for i in range(i, i + dataset.shape[0]):\n",
    "        \n",
    "        datapoint = dataset.loc[i]\n",
    "        #-------------------------------------------\n",
    "        #print('data point:', '\\n', datapoint, '\\n')\n",
    "        #-------------------------------------------\n",
    "        \n",
    "        # go through features in data\n",
    "        for feature in data:\n",
    "            \n",
    "            value = datapoint[feature]\n",
    "            #----------------------------------------\n",
    "            #print('value is: ', value)\n",
    "            #----------------------------------------    \n",
    "            if isinstance(value, str):\n",
    "                value = value.lower()\n",
    "\n",
    "            if feature == 'location':\n",
    "\n",
    "                if str(value) == 'nan':\n",
    "                    #-------------------------------------------------\n",
    "                    #if value in data[feature]:\n",
    "                        #print(value, ' not in data with key', feature)\n",
    "                    #-------------------------------------------------\n",
    "                    if value in data[feature]:\n",
    "                        #print(value, ' in data with key', feature)\n",
    "                        datapoint_prob_0.append(data[feature][value][0])\n",
    "                        datapoint_prob_1.append(data[feature][value][1])\n",
    "                    \n",
    "                else:\n",
    "                    temp = value.split(',')\n",
    "                    #--------------------------------------------\n",
    "                    #if temp[0] not in data[feature]:\n",
    "                        #print(temp[0], ' not in data with key', feature)\n",
    "                    #--------------------------------------------\n",
    "                    \n",
    "                    # NOTE: here we just picking the first location but some data points have sets of locations so we need\n",
    "                    # to consider each location of that data point.\n",
    "                    \n",
    "                    if temp[0] in data[feature]:\n",
    "                        #print(temp[0], ' in data with key', feature)\n",
    "                        datapoint_prob_0.append(data[feature][temp[0]][0])\n",
    "                        datapoint_prob_1.append(data[feature][temp[0]][1])\n",
    "            else:\n",
    "                #----------------------------------------\n",
    "                #if value not in data[feature]:\n",
    "                    #print(value, ' not in data with key', feature)\n",
    "                #----------------------------------------\n",
    "                if value in data[feature]:\n",
    "                    #print(value, ' in data with key', feature)\n",
    "                    datapoint_prob_0.append(data[feature][value][0])\n",
    "                    datapoint_prob_1.append(data[feature][value][1])\n",
    "\n",
    "        #print('length of lists respectively: ', len(datapoint_prob_0), ' ', len(datapoint_prob_1))\n",
    "        \n",
    "        given_fraud_false = np.prod(datapoint_prob_0) * prior_prob_fraud_false\n",
    "        given_fraud_true = np.prod(datapoint_prob_1) * prior_prob_fraud_true\n",
    "\n",
    "        bayes_numerator.append(given_fraud_false)\n",
    "        bayes_numerator.append(given_fraud_true)\n",
    "\n",
    "        #print()\n",
    "        print('job posting: ', datapoint['title'])\n",
    "        print('bayes numerator given job posting IS NOT fraudulent: ', bayes_numerator[0])\n",
    "        print('bayes numerator given job posting IS fraudulent: ', bayes_numerator[1])\n",
    "\n",
    "        max_value = max(bayes_numerator)\n",
    "        if max_value == bayes_numerator[0]:\n",
    "            print('classification is: ', 0, ' not fraudulent', '\\n\\n')\n",
    "        else:\n",
    "            print('classification is: ', 1, ' fraudulent', '\\n\\n')\n",
    "            \n",
    "        # clear lists for next data point classification\n",
    "        datapoint_prob_0.clear()\n",
    "        datapoint_prob_1.clear()\n",
    "        bayes_numerator.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job posting:  Senior Front-End Engineer\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6273116597897598\n",
      "bayes numerator given job posting IS fraudulent:  2.881831732158109e-17\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Field Sales Representative\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6306537476832029\n",
      "bayes numerator given job posting IS fraudulent:  1.3864771398482194e-16\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Field Supervisor\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6120107109683527\n",
      "bayes numerator given job posting IS fraudulent:  7.937900187126495e-18\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Systems Engineers/Network Administrators/Tiers I-III\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6862303467569415\n",
      "bayes numerator given job posting IS fraudulent:  7.608869670342588e-16\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Customer Service Associate\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.566618413856038\n",
      "bayes numerator given job posting IS fraudulent:  1.8391452249870562e-17\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Customer Service Associate\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.566618413856038\n",
      "bayes numerator given job posting IS fraudulent:  1.8391452249870562e-17\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  .NET Developer - NexLP\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.5971482558489499\n",
      "bayes numerator given job posting IS fraudulent:  2.8922358849368064e-16\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  PT Environmental Educator\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6752407004814022\n",
      "bayes numerator given job posting IS fraudulent:  6.611272929655523e-16\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  CASH In Hand Job (Part-Time Staff Needed)\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.5246369883110856\n",
      "bayes numerator given job posting IS fraudulent:  1.709913676600122e-16\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Front End JS Developer\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6321174849830259\n",
      "bayes numerator given job posting IS fraudulent:  6.674421796710407e-18\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Sysadmin\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6858047611366318\n",
      "bayes numerator given job posting IS fraudulent:  1.2179257042383728e-13\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Sales Representative with Management Training - AT&T\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6261829941140177\n",
      "bayes numerator given job posting IS fraudulent:  2.3414668285707545e-14\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Regional Inside Sales Representative\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.5346878254040902\n",
      "bayes numerator given job posting IS fraudulent:  6.477730808689427e-15\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Maintenance Mechanic\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.5551581686852538\n",
      "bayes numerator given job posting IS fraudulent:  1.756768376374601e-13\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Messenger Courier\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.5707847257226264\n",
      "bayes numerator given job posting IS fraudulent:  2.5196289582322673e-15\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Project Manager\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6406952607606953\n",
      "bayes numerator given job posting IS fraudulent:  1.3817115205910505e-16\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  English Teacher Abroad\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6502219938830077\n",
      "bayes numerator given job posting IS fraudulent:  6.407572416016056e-22\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Sales Associate\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.6084503696771432\n",
      "bayes numerator given job posting IS fraudulent:  5.86277693511761e-16\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Manufacturing Engineer\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.5137409197145006\n",
      "bayes numerator given job posting IS fraudulent:  2.5377128463626264e-16\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n",
      "job posting:  Purchasing Manager\n",
      "bayes numerator given job posting IS NOT fraudulent:  0.7684749140081116\n",
      "bayes numerator given job posting IS fraudulent:  8.101005609584989e-13\n",
      "classification is:  0  not fraudulent \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#----------------------------------------------------------------\n",
    "# just for illustration but not to be used as a way to determine the performance of the model, cause this is training data\n",
    "\n",
    "# for training data slicing starts at 0 and ends at 10728\n",
    "#classify_job_postings(training_data.loc[:20])\n",
    "\n",
    "# NOTE: there's a job posting thats fraudulent in the range of training data specified below but its classified as 0 (non fraud), \n",
    "# however this can be due to a number of reasons but before we can dive into those we must ensure the \n",
    "# classify_data_point function is working correctly for multiple data points of each feature.\n",
    "\n",
    "#classify_job_postings(training_data.loc[97:105])\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "# for evaluating performance of model we use validation and test data\n",
    "\n",
    "# for validation data slicing starts at 10729 and ends at 16450\n",
    "classify_job_postings(validation_data.loc[10729:10748])\n",
    "\n",
    "# for test data slicing starts at 16451 till the end of the test data. \n",
    "#classify_job_postings(test_data.loc[16451:16470])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
